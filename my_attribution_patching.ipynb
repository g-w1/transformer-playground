{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYg82mUMGS0A"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Attribution_Patching_Demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1jw-pJAGS0D"
   },
   "source": [
    " # Attribution Patching Demo\n",
    " **Read [the accompanying blog post here](https://neelnanda.io/attribution-patching) for more context**\n",
    " This is an interim research report, giving a whirlwind tour of some unpublished work I did at Anthropic (credit to the then team - Chris Olah, Catherine Olsson, Nelson Elhage and Tristan Hume for help, support, and mentorship!)\n",
    "\n",
    " The goal of this work is run activation patching at an industrial scale, by using gradient based attribution to approximate the technique - allow an arbitrary number of patches to be made on two forwards and a single backward pass\n",
    "\n",
    " I have had less time than hoped to flesh out this investigation, but am writing up a rough investigation and comparison to standard activation patching on a few tasks to give a sense of the potential of this approach, and where it works vs falls down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIBPbSBRGS0G"
   },
   "source": [
    " <b style=\"color: red\">To use this notebook, go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.</b>\n",
    "\n",
    " **Tips for reading this Colab:**\n",
    " * You can run all this code for yourself!\n",
    " * The graphs are interactive!\n",
    " * Use the table of contents pane in the sidebar to navigate\n",
    " * Collapse irrelevant sections with the dropdown arrows\n",
    " * Search the page using the search in the sidebar, not CTRL+F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v14ANm-9GS0H"
   },
   "source": [
    " ## Setup (Ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKDcoZqVGS0I",
    "outputId": "322e5284-720f-46e8-d068-7ec40f4cfe15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: NODE_OPTIONS=--openssl-legacy-provider # nodejs is SOOO janky wtf bro\n",
      "Running as a Jupyter notebook - intended for development only!\n",
      "Requirement already satisfied: transformer_lens in /usr/local/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.11/site-packages (from transformer_lens) (0.24.1)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.11/site-packages (from transformer_lens) (0.14.1)\n",
      "Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.11/site-packages (from transformer_lens) (2.14.7)\n",
      "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/site-packages (from transformer_lens) (0.7.0)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.11/site-packages (from transformer_lens) (0.0.3)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.11/site-packages (from transformer_lens) (0.2.23)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/site-packages (from transformer_lens) (1.25.2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/site-packages (from transformer_lens) (2.1.0)\n",
      "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.11/site-packages (from transformer_lens) (13.7.0)\n",
      "Requirement already satisfied: torch!=2.0,!=2.1.0,>=1.10 in /usr/local/lib/python3.11/site-packages (from transformer_lens) (2.1.1)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/site-packages (from transformer_lens) (4.65.0)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.11/site-packages (from transformer_lens) (4.35.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/site-packages (from transformer_lens) (4.5.0)\n",
      "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.11/site-packages (from transformer_lens) (0.16.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer_lens) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer_lens) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer_lens) (0.19.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (0.5)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (2.30.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/site-packages (from datasets>=2.7.1->transformer_lens) (3.8.5)\n",
      "Requirement already satisfied: typeguard<3,>=2.13.3 in /usr/local/lib/python3.11/site-packages (from jaxtyping>=0.2.11->transformer_lens) (2.13.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas>=1.1.5->transformer_lens) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/site-packages (from pandas>=1.1.5->transformer_lens) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/site-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/site-packages (from rich>=12.6.0->transformer_lens) (2.15.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.13.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers>=4.25.1->transformer_lens) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/site-packages (from transformers>=4.25.1->transformer_lens) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/site-packages (from transformers>=4.25.1->transformer_lens) (0.4.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/site-packages (from wandb>=0.13.5->transformer_lens) (8.1.3)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/site-packages (from wandb>=0.13.5->transformer_lens) (3.1.40)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.11/site-packages (from wandb>=0.13.5->transformer_lens) (1.35.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/site-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/site-packages (from wandb>=0.13.5->transformer_lens) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from wandb>=0.13.5->transformer_lens) (68.2.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.11/site-packages (from wandb>=0.13.5->transformer_lens) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.11/site-packages (from wandb>=0.13.5->transformer_lens) (4.23.4)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.11)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/site-packages (from sympy->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchtyping in /usr/local/lib/python3.11/site-packages (0.1.4)\n",
      "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/site-packages (from torchtyping) (2.1.1)\n",
      "Requirement already satisfied: typeguard>=2.11.1 in /usr/local/lib/python3.11/site-packages (from torchtyping) (2.13.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch>=1.7.0->torchtyping) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.7.0->torchtyping) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/site-packages (from sympy->torch>=1.7.0->torchtyping) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/neelnanda-io/neel-plotly.git\n",
      "  Cloning https://github.com/neelnanda-io/neel-plotly.git to /private/var/folders/tv/bgwf6pv92m935jtjh44g8bmr0000gn/T/pip-req-build-34102l5m\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/neel-plotly.git /private/var/folders/tv/bgwf6pv92m935jtjh44g8bmr0000gn/T/pip-req-build-34102l5m\n",
      "  Resolved https://github.com/neelnanda-io/neel-plotly.git to commit 6dc24b26f8dec991908479d7445dae496b3430b7\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: einops in /usr/local/lib/python3.11/site-packages (from neel-plotly==0.0.0) (0.7.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from neel-plotly==0.0.0) (1.25.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/site-packages (from neel-plotly==0.0.0) (2.1.1)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.11/site-packages (from neel-plotly==0.0.0) (5.18.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from neel-plotly==0.0.0) (4.65.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (from neel-plotly==0.0.0) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas->neel-plotly==0.0.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas->neel-plotly==0.0.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/site-packages (from pandas->neel-plotly==0.0.0) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/site-packages (from plotly->neel-plotly==0.0.0) (8.2.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from plotly->neel-plotly==0.0.0) (23.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch->neel-plotly==0.0.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/site-packages (from torch->neel-plotly==0.0.0) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch->neel-plotly==0.0.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch->neel-plotly==0.0.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch->neel-plotly==0.0.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch->neel-plotly==0.0.0) (2023.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->neel-plotly==0.0.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch->neel-plotly==0.0.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/site-packages (from sympy->torch->neel-plotly==0.0.0) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/austinleedavis/PySvelte-fixColabSetup.git\n",
      "  Cloning https://github.com/austinleedavis/PySvelte-fixColabSetup.git to /private/var/folders/tv/bgwf6pv92m935jtjh44g8bmr0000gn/T/pip-req-build-i9vnbp2r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/austinleedavis/PySvelte-fixColabSetup.git /private/var/folders/tv/bgwf6pv92m935jtjh44g8bmr0000gn/T/pip-req-build-i9vnbp2r\n",
      "  Resolved https://github.com/austinleedavis/PySvelte-fixColabSetup.git to commit c414913707944a61594bd5f97ac167b6a7b3b8e1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: einops in /usr/local/lib/python3.11/site-packages (from PySvelte==1.0.0) (0.7.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from PySvelte==1.0.0) (1.25.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/site-packages (from PySvelte==1.0.0) (2.1.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/site-packages (from PySvelte==1.0.0) (2.14.7)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (from PySvelte==1.0.0) (4.35.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from PySvelte==1.0.0) (4.65.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (from PySvelte==1.0.0) (2.1.0)\n",
      "Requirement already satisfied: typeguard~=2.0 in /usr/local/lib/python3.11/site-packages (from PySvelte==1.0.0) (2.13.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/site-packages (from datasets->PySvelte==1.0.0) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/site-packages (from datasets->PySvelte==1.0.0) (0.5)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/site-packages (from datasets->PySvelte==1.0.0) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/site-packages (from datasets->PySvelte==1.0.0) (2.30.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/site-packages (from datasets->PySvelte==1.0.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/site-packages (from datasets->PySvelte==1.0.0) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->PySvelte==1.0.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/site-packages (from datasets->PySvelte==1.0.0) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/site-packages (from datasets->PySvelte==1.0.0) (0.19.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from datasets->PySvelte==1.0.0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from datasets->PySvelte==1.0.0) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas->PySvelte==1.0.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas->PySvelte==1.0.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/site-packages (from pandas->PySvelte==1.0.0) (2023.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch->PySvelte==1.0.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/site-packages (from torch->PySvelte==1.0.0) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch->PySvelte==1.0.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch->PySvelte==1.0.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch->PySvelte==1.0.0) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers->PySvelte==1.0.0) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/site-packages (from transformers->PySvelte==1.0.0) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/site-packages (from transformers->PySvelte==1.0.0) (0.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets->PySvelte==1.0.0) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets->PySvelte==1.0.0) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets->PySvelte==1.0.0) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets->PySvelte==1.0.0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->PySvelte==1.0.0) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch->PySvelte==1.0.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/site-packages (from sympy->torch->PySvelte==1.0.0) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.11/site-packages (2.13.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tv/bgwf6pv92m935jtjh44g8bmr0000gn/T/ipykernel_56379/3292126430.py:30: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/var/folders/tv/bgwf6pv92m935jtjh44g8bmr0000gn/T/ipykernel_56379/3292126430.py:31: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
    "DEBUG_MODE = False\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "    %pip install transformer_lens\n",
    "    %pip install torchtyping\n",
    "    # Install my janky personal plotting utils\n",
    "    %pip install git+https://github.com/neelnanda-io/neel-plotly.git\n",
    "    # Install another version of node that makes PySvelte work way faster\n",
    "    !sudo apt-get install -y nodejs\n",
    "    %pip install git+https://github.com/austinleedavis/PySvelte-fixColabSetup.git\n",
    "    # Needed for PySvelte to work, v3 came out and broke things...\n",
    "    %pip install typeguard==2.13.3\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    %env NODE_OPTIONS=--openssl-legacy-provider # nodejs is SOOO janky wtf bro\n",
    "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "    from IPython import get_ipython\n",
    "    %pip install transformer_lens\n",
    "    %pip install torchtyping\n",
    "    # Install my janky personal plotting utils\n",
    "    %pip install git+https://github.com/neelnanda-io/neel-plotly.git\n",
    "    %pip install git+https://github.com/austinleedavis/PySvelte-fixColabSetup.git\n",
    "    # Needed for PySvelte to work, v3 came out and broke things...\n",
    "    %pip install typeguard==2.13.3\n",
    "    ipython = get_ipython()\n",
    "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "    ipython.magic(\"load_ext autoreload\")\n",
    "    ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VVh0oNBiGS0M"
   },
   "outputs": [],
   "source": [
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "\n",
    "if IN_COLAB or not DEBUG_MODE:\n",
    "    # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n",
    "    pio.renderers.default = \"colab\"\n",
    "else:\n",
    "    pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "HWPUy-4UGS0P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.notebook as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtyping import TensorType as TT\n",
    "from typing import List, Union, Optional, Callable\n",
    "from functools import partial\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "00MJPdZAGS0P"
   },
   "outputs": [],
   "source": [
    "import pysvelte\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODCQZEk2GS0Q"
   },
   "source": [
    " Plotting helper functions from a janky personal library of plotting utils. The library is not documented and I recommend against trying to read it, just use your preferred plotting library if you want to do anything non-obvious:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QDv_fOfQGS0S"
   },
   "outputs": [],
   "source": [
    "from neel_plotly import line, imshow, scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "SBQwFp4nGS0T"
   },
   "outputs": [],
   "source": [
    "import transformer_lens.patching as patching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KlyM2xtGS0T"
   },
   "source": [
    " ## IOI Patching Setup\n",
    " This just copies the relevant set up from Exploratory Analysis Demo, and isn't very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true,
     "referenced_widgets": [
      "1bde56125ee149eb91e96ca58faa81f7",
      "443abb49a6204d4db1a03271d487722e",
      "86a2545f30ca4385a75c6748a3f47479",
      "b583dd4c68a74faaacda421cd7051ce2",
      "7752268877c84615b8d9e258439a3501",
      "9cfa9769f82d4df7a41041ff69f77805"
     ]
    },
    "id": "CBPPDYn0GS0T",
    "outputId": "0df734e1-586e-414c-a81f-d0efe5011ff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")\n",
    "model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "SSrcYE3PGS0U",
    "outputId": "7532e6dd-f8a2-4e09-a9bc-35a0cf7ff74c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean string 0 <|endoftext|>When John and Mary went to the shops, John gave the bag to\n",
      "Corrupted string 0 <|endoftext|>When John and Mary went to the shops, Mary gave the bag to\n",
      "Answer token indices tensor([[ 5335,  1757],\n",
      "        [ 1757,  5335],\n",
      "        [ 4186,  3700],\n",
      "        [ 3700,  4186],\n",
      "        [ 6035, 15686],\n",
      "        [15686,  6035],\n",
      "        [ 5780, 14235],\n",
      "        [14235,  5780]])\n"
     ]
    }
   ],
   "source": [
    "prompts = ['When John and Mary went to the shops, John gave the bag to', 'When John and Mary went to the shops, Mary gave the bag to', 'When Tom and James went to the park, James gave the ball to', 'When Tom and James went to the park, Tom gave the ball to', 'When Dan and Sid went to the shops, Sid gave an apple to', 'When Dan and Sid went to the shops, Dan gave an apple to', 'After Martin and Amy went to the park, Amy gave a drink to', 'After Martin and Amy went to the park, Martin gave a drink to']\n",
    "answers = [(' Mary', ' John'), (' John', ' Mary'), (' Tom', ' James'), (' James', ' Tom'), (' Dan', ' Sid'), (' Sid', ' Dan'), (' Martin', ' Amy'), (' Amy', ' Martin')]\n",
    "\n",
    "clean_tokens = model.to_tokens(prompts)\n",
    "# Swap each adjacent pair, with a hacky list comprehension\n",
    "corrupted_tokens = clean_tokens[\n",
    "    [(i+1 if i%2==0 else i-1) for i in range(len(clean_tokens)) ]\n",
    "    ]\n",
    "print(\"Clean string 0\", model.to_string(clean_tokens[0]))\n",
    "print(\"Corrupted string 0\", model.to_string(corrupted_tokens[0]))\n",
    "\n",
    "answer_token_indices = torch.tensor([[model.to_single_token(answers[i][j]) for j in range(2)] for i in range(len(answers))], device=model.cfg.device)\n",
    "print(\"Answer token indices\", answer_token_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "AWSEWKXtGS0U",
    "outputId": "1ef4a63a-cc81-4ae4-d704-541aac138262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean logit diff: 3.5519\n",
      "Corrupted logit diff: -3.5519\n"
     ]
    }
   ],
   "source": [
    "def get_logit_diff(logits, answer_token_indices=answer_token_indices):\n",
    "    if len(logits.shape)==3:\n",
    "        # Get final logits only\n",
    "        logits = logits[:, -1, :]\n",
    "    correct_logits = logits.gather(1, answer_token_indices[:, 0].unsqueeze(1))\n",
    "    incorrect_logits = logits.gather(1, answer_token_indices[:, 1].unsqueeze(1))\n",
    "    return (correct_logits - incorrect_logits).mean()\n",
    "\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "\n",
    "clean_logit_diff = get_logit_diff(clean_logits, answer_token_indices).item()\n",
    "print(f\"Clean logit diff: {clean_logit_diff:.4f}\")\n",
    "\n",
    "corrupted_logit_diff = get_logit_diff(corrupted_logits, answer_token_indices).item()\n",
    "print(f\"Corrupted logit diff: {corrupted_logit_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4g-QH0epGS0V",
    "outputId": "a0ccf55a-2c05-49f2-b607-0445c81d1904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Baseline is 1: 1.0000\n",
      "Corrupted Baseline is 0: 0.0000\n"
     ]
    }
   ],
   "source": [
    "CLEAN_BASELINE = clean_logit_diff\n",
    "CORRUPTED_BASELINE = corrupted_logit_diff\n",
    "def ioi_metric(logits, answer_token_indices=answer_token_indices):\n",
    "    return (get_logit_diff(logits, answer_token_indices) - CORRUPTED_BASELINE) / (CLEAN_BASELINE  - CORRUPTED_BASELINE)\n",
    "\n",
    "print(f\"Clean Baseline is 1: {ioi_metric(clean_logits).item():.4f}\")\n",
    "print(f\"Corrupted Baseline is 0: {ioi_metric(corrupted_logits).item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0NERF3ZGS0Y"
   },
   "source": [
    " ## Patching\n",
    " In the following cells, we define attribution patching and use it in various ways on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "76EzeN3JGS0h"
   },
   "outputs": [],
   "source": [
    "Metric = Callable[[TT[\"batch_and_pos_dims\", \"d_model\"]], float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "p29-3iJDGS0i",
    "outputId": "2500a9f9-1aed-43e4-f97c-8aa962ec527f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Value: 1.0\n",
      "Clean Activations Cached: 220\n",
      "Clean Gradients Cached: 220\n",
      "Corrupted Value: 0.0\n",
      "Corrupted Activations Cached: 220\n",
      "Corrupted Gradients Cached: 220\n",
      "Clean cache: ActivationCache with keys ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.attn.hook_result', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.attn.hook_result', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.attn.hook_result', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.attn.hook_result', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.attn.hook_result', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.attn.hook_result', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.attn.hook_result', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.attn.hook_result', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.attn.hook_result', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.attn.hook_result', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.attn.hook_result', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.attn.hook_result', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized']\n",
      "Clean grad cache: ActivationCache with keys ['ln_final.hook_normalized', 'ln_final.hook_scale', 'blocks.11.hook_resid_post', 'blocks.11.hook_mlp_out', 'blocks.11.mlp.hook_post', 'blocks.11.mlp.hook_pre', 'blocks.11.ln2.hook_normalized', 'blocks.11.ln2.hook_scale', 'blocks.11.hook_resid_mid', 'blocks.11.hook_attn_out', 'blocks.11.attn.hook_result', 'blocks.11.attn.hook_z', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_q', 'blocks.11.ln1.hook_normalized', 'blocks.11.ln1.hook_scale', 'blocks.11.hook_resid_pre', 'blocks.10.hook_resid_post', 'blocks.10.hook_mlp_out', 'blocks.10.mlp.hook_post', 'blocks.10.mlp.hook_pre', 'blocks.10.ln2.hook_normalized', 'blocks.10.ln2.hook_scale', 'blocks.10.hook_resid_mid', 'blocks.10.hook_attn_out', 'blocks.10.attn.hook_result', 'blocks.10.attn.hook_z', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_q', 'blocks.10.ln1.hook_normalized', 'blocks.10.ln1.hook_scale', 'blocks.10.hook_resid_pre', 'blocks.9.hook_resid_post', 'blocks.9.hook_mlp_out', 'blocks.9.mlp.hook_post', 'blocks.9.mlp.hook_pre', 'blocks.9.ln2.hook_normalized', 'blocks.9.ln2.hook_scale', 'blocks.9.hook_resid_mid', 'blocks.9.hook_attn_out', 'blocks.9.attn.hook_result', 'blocks.9.attn.hook_z', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_q', 'blocks.9.ln1.hook_normalized', 'blocks.9.ln1.hook_scale', 'blocks.9.hook_resid_pre', 'blocks.8.hook_resid_post', 'blocks.8.hook_mlp_out', 'blocks.8.mlp.hook_post', 'blocks.8.mlp.hook_pre', 'blocks.8.ln2.hook_normalized', 'blocks.8.ln2.hook_scale', 'blocks.8.hook_resid_mid', 'blocks.8.hook_attn_out', 'blocks.8.attn.hook_result', 'blocks.8.attn.hook_z', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_q', 'blocks.8.ln1.hook_normalized', 'blocks.8.ln1.hook_scale', 'blocks.8.hook_resid_pre', 'blocks.7.hook_resid_post', 'blocks.7.hook_mlp_out', 'blocks.7.mlp.hook_post', 'blocks.7.mlp.hook_pre', 'blocks.7.ln2.hook_normalized', 'blocks.7.ln2.hook_scale', 'blocks.7.hook_resid_mid', 'blocks.7.hook_attn_out', 'blocks.7.attn.hook_result', 'blocks.7.attn.hook_z', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_q', 'blocks.7.ln1.hook_normalized', 'blocks.7.ln1.hook_scale', 'blocks.7.hook_resid_pre', 'blocks.6.hook_resid_post', 'blocks.6.hook_mlp_out', 'blocks.6.mlp.hook_post', 'blocks.6.mlp.hook_pre', 'blocks.6.ln2.hook_normalized', 'blocks.6.ln2.hook_scale', 'blocks.6.hook_resid_mid', 'blocks.6.hook_attn_out', 'blocks.6.attn.hook_result', 'blocks.6.attn.hook_z', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_q', 'blocks.6.ln1.hook_normalized', 'blocks.6.ln1.hook_scale', 'blocks.6.hook_resid_pre', 'blocks.5.hook_resid_post', 'blocks.5.hook_mlp_out', 'blocks.5.mlp.hook_post', 'blocks.5.mlp.hook_pre', 'blocks.5.ln2.hook_normalized', 'blocks.5.ln2.hook_scale', 'blocks.5.hook_resid_mid', 'blocks.5.hook_attn_out', 'blocks.5.attn.hook_result', 'blocks.5.attn.hook_z', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_q', 'blocks.5.ln1.hook_normalized', 'blocks.5.ln1.hook_scale', 'blocks.5.hook_resid_pre', 'blocks.4.hook_resid_post', 'blocks.4.hook_mlp_out', 'blocks.4.mlp.hook_post', 'blocks.4.mlp.hook_pre', 'blocks.4.ln2.hook_normalized', 'blocks.4.ln2.hook_scale', 'blocks.4.hook_resid_mid', 'blocks.4.hook_attn_out', 'blocks.4.attn.hook_result', 'blocks.4.attn.hook_z', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_q', 'blocks.4.ln1.hook_normalized', 'blocks.4.ln1.hook_scale', 'blocks.4.hook_resid_pre', 'blocks.3.hook_resid_post', 'blocks.3.hook_mlp_out', 'blocks.3.mlp.hook_post', 'blocks.3.mlp.hook_pre', 'blocks.3.ln2.hook_normalized', 'blocks.3.ln2.hook_scale', 'blocks.3.hook_resid_mid', 'blocks.3.hook_attn_out', 'blocks.3.attn.hook_result', 'blocks.3.attn.hook_z', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_q', 'blocks.3.ln1.hook_normalized', 'blocks.3.ln1.hook_scale', 'blocks.3.hook_resid_pre', 'blocks.2.hook_resid_post', 'blocks.2.hook_mlp_out', 'blocks.2.mlp.hook_post', 'blocks.2.mlp.hook_pre', 'blocks.2.ln2.hook_normalized', 'blocks.2.ln2.hook_scale', 'blocks.2.hook_resid_mid', 'blocks.2.hook_attn_out', 'blocks.2.attn.hook_result', 'blocks.2.attn.hook_z', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_q', 'blocks.2.ln1.hook_normalized', 'blocks.2.ln1.hook_scale', 'blocks.2.hook_resid_pre', 'blocks.1.hook_resid_post', 'blocks.1.hook_mlp_out', 'blocks.1.mlp.hook_post', 'blocks.1.mlp.hook_pre', 'blocks.1.ln2.hook_normalized', 'blocks.1.ln2.hook_scale', 'blocks.1.hook_resid_mid', 'blocks.1.hook_attn_out', 'blocks.1.attn.hook_result', 'blocks.1.attn.hook_z', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_q', 'blocks.1.ln1.hook_normalized', 'blocks.1.ln1.hook_scale', 'blocks.1.hook_resid_pre', 'blocks.0.hook_resid_post', 'blocks.0.hook_mlp_out', 'blocks.0.mlp.hook_post', 'blocks.0.mlp.hook_pre', 'blocks.0.ln2.hook_normalized', 'blocks.0.ln2.hook_scale', 'blocks.0.hook_resid_mid', 'blocks.0.hook_attn_out', 'blocks.0.attn.hook_result', 'blocks.0.attn.hook_z', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_q', 'blocks.0.ln1.hook_normalized', 'blocks.0.ln1.hook_scale', 'blocks.0.hook_resid_pre', 'hook_pos_embed', 'hook_embed']\n",
      "Corrupted cache: ActivationCache with keys ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.attn.hook_result', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.attn.hook_result', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.attn.hook_result', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.attn.hook_result', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.attn.hook_result', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.attn.hook_result', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.attn.hook_result', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.attn.hook_result', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.attn.hook_result', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.attn.hook_result', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.attn.hook_result', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.attn.hook_result', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized']\n",
      "Corrupted grad cache: ActivationCache with keys ['ln_final.hook_normalized', 'ln_final.hook_scale', 'blocks.11.hook_resid_post', 'blocks.11.hook_mlp_out', 'blocks.11.mlp.hook_post', 'blocks.11.mlp.hook_pre', 'blocks.11.ln2.hook_normalized', 'blocks.11.ln2.hook_scale', 'blocks.11.hook_resid_mid', 'blocks.11.hook_attn_out', 'blocks.11.attn.hook_result', 'blocks.11.attn.hook_z', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_q', 'blocks.11.ln1.hook_normalized', 'blocks.11.ln1.hook_scale', 'blocks.11.hook_resid_pre', 'blocks.10.hook_resid_post', 'blocks.10.hook_mlp_out', 'blocks.10.mlp.hook_post', 'blocks.10.mlp.hook_pre', 'blocks.10.ln2.hook_normalized', 'blocks.10.ln2.hook_scale', 'blocks.10.hook_resid_mid', 'blocks.10.hook_attn_out', 'blocks.10.attn.hook_result', 'blocks.10.attn.hook_z', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_q', 'blocks.10.ln1.hook_normalized', 'blocks.10.ln1.hook_scale', 'blocks.10.hook_resid_pre', 'blocks.9.hook_resid_post', 'blocks.9.hook_mlp_out', 'blocks.9.mlp.hook_post', 'blocks.9.mlp.hook_pre', 'blocks.9.ln2.hook_normalized', 'blocks.9.ln2.hook_scale', 'blocks.9.hook_resid_mid', 'blocks.9.hook_attn_out', 'blocks.9.attn.hook_result', 'blocks.9.attn.hook_z', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_q', 'blocks.9.ln1.hook_normalized', 'blocks.9.ln1.hook_scale', 'blocks.9.hook_resid_pre', 'blocks.8.hook_resid_post', 'blocks.8.hook_mlp_out', 'blocks.8.mlp.hook_post', 'blocks.8.mlp.hook_pre', 'blocks.8.ln2.hook_normalized', 'blocks.8.ln2.hook_scale', 'blocks.8.hook_resid_mid', 'blocks.8.hook_attn_out', 'blocks.8.attn.hook_result', 'blocks.8.attn.hook_z', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_q', 'blocks.8.ln1.hook_normalized', 'blocks.8.ln1.hook_scale', 'blocks.8.hook_resid_pre', 'blocks.7.hook_resid_post', 'blocks.7.hook_mlp_out', 'blocks.7.mlp.hook_post', 'blocks.7.mlp.hook_pre', 'blocks.7.ln2.hook_normalized', 'blocks.7.ln2.hook_scale', 'blocks.7.hook_resid_mid', 'blocks.7.hook_attn_out', 'blocks.7.attn.hook_result', 'blocks.7.attn.hook_z', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_q', 'blocks.7.ln1.hook_normalized', 'blocks.7.ln1.hook_scale', 'blocks.7.hook_resid_pre', 'blocks.6.hook_resid_post', 'blocks.6.hook_mlp_out', 'blocks.6.mlp.hook_post', 'blocks.6.mlp.hook_pre', 'blocks.6.ln2.hook_normalized', 'blocks.6.ln2.hook_scale', 'blocks.6.hook_resid_mid', 'blocks.6.hook_attn_out', 'blocks.6.attn.hook_result', 'blocks.6.attn.hook_z', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_q', 'blocks.6.ln1.hook_normalized', 'blocks.6.ln1.hook_scale', 'blocks.6.hook_resid_pre', 'blocks.5.hook_resid_post', 'blocks.5.hook_mlp_out', 'blocks.5.mlp.hook_post', 'blocks.5.mlp.hook_pre', 'blocks.5.ln2.hook_normalized', 'blocks.5.ln2.hook_scale', 'blocks.5.hook_resid_mid', 'blocks.5.hook_attn_out', 'blocks.5.attn.hook_result', 'blocks.5.attn.hook_z', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_q', 'blocks.5.ln1.hook_normalized', 'blocks.5.ln1.hook_scale', 'blocks.5.hook_resid_pre', 'blocks.4.hook_resid_post', 'blocks.4.hook_mlp_out', 'blocks.4.mlp.hook_post', 'blocks.4.mlp.hook_pre', 'blocks.4.ln2.hook_normalized', 'blocks.4.ln2.hook_scale', 'blocks.4.hook_resid_mid', 'blocks.4.hook_attn_out', 'blocks.4.attn.hook_result', 'blocks.4.attn.hook_z', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_q', 'blocks.4.ln1.hook_normalized', 'blocks.4.ln1.hook_scale', 'blocks.4.hook_resid_pre', 'blocks.3.hook_resid_post', 'blocks.3.hook_mlp_out', 'blocks.3.mlp.hook_post', 'blocks.3.mlp.hook_pre', 'blocks.3.ln2.hook_normalized', 'blocks.3.ln2.hook_scale', 'blocks.3.hook_resid_mid', 'blocks.3.hook_attn_out', 'blocks.3.attn.hook_result', 'blocks.3.attn.hook_z', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_q', 'blocks.3.ln1.hook_normalized', 'blocks.3.ln1.hook_scale', 'blocks.3.hook_resid_pre', 'blocks.2.hook_resid_post', 'blocks.2.hook_mlp_out', 'blocks.2.mlp.hook_post', 'blocks.2.mlp.hook_pre', 'blocks.2.ln2.hook_normalized', 'blocks.2.ln2.hook_scale', 'blocks.2.hook_resid_mid', 'blocks.2.hook_attn_out', 'blocks.2.attn.hook_result', 'blocks.2.attn.hook_z', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_q', 'blocks.2.ln1.hook_normalized', 'blocks.2.ln1.hook_scale', 'blocks.2.hook_resid_pre', 'blocks.1.hook_resid_post', 'blocks.1.hook_mlp_out', 'blocks.1.mlp.hook_post', 'blocks.1.mlp.hook_pre', 'blocks.1.ln2.hook_normalized', 'blocks.1.ln2.hook_scale', 'blocks.1.hook_resid_mid', 'blocks.1.hook_attn_out', 'blocks.1.attn.hook_result', 'blocks.1.attn.hook_z', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_q', 'blocks.1.ln1.hook_normalized', 'blocks.1.ln1.hook_scale', 'blocks.1.hook_resid_pre', 'blocks.0.hook_resid_post', 'blocks.0.hook_mlp_out', 'blocks.0.mlp.hook_post', 'blocks.0.mlp.hook_pre', 'blocks.0.ln2.hook_normalized', 'blocks.0.ln2.hook_scale', 'blocks.0.hook_resid_mid', 'blocks.0.hook_attn_out', 'blocks.0.attn.hook_result', 'blocks.0.attn.hook_z', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_q', 'blocks.0.ln1.hook_normalized', 'blocks.0.ln1.hook_scale', 'blocks.0.hook_resid_pre', 'hook_pos_embed', 'hook_embed']\n"
     ]
    }
   ],
   "source": [
    "filter_not_qkv_input = lambda name: \"_input\" not in name and \"attn_in\" not in name and \"hook_mlp_in\" not in name\n",
    "def get_cache_fwd_and_bwd(model, tokens, metric):\n",
    "    model.reset_hooks()\n",
    "    cache = {}\n",
    "    def forward_cache_hook(act, hook):\n",
    "        cache[hook.name] = act.detach()\n",
    "    model.add_hook(filter_not_qkv_input, forward_cache_hook, \"fwd\")\n",
    "\n",
    "    grad_cache = {}\n",
    "    def backward_cache_hook(act, hook):\n",
    "        grad_cache[hook.name] = act.detach()\n",
    "    model.add_hook(filter_not_qkv_input, backward_cache_hook, \"bwd\")\n",
    "\n",
    "    value = metric(model(tokens))\n",
    "    value.backward()\n",
    "    model.reset_hooks()\n",
    "    return value.item(), ActivationCache(cache, model), ActivationCache(grad_cache, model)\n",
    "\n",
    "clean_value, clean_cache, clean_grad_cache = get_cache_fwd_and_bwd(model, clean_tokens, ioi_metric)\n",
    "print(\"Clean Value:\", clean_value)\n",
    "print(\"Clean Activations Cached:\", len(clean_cache))\n",
    "print(\"Clean Gradients Cached:\", len(clean_grad_cache))\n",
    "corrupted_value, corrupted_cache, corrupted_grad_cache = get_cache_fwd_and_bwd(model, corrupted_tokens, ioi_metric)\n",
    "print(\"Corrupted Value:\", corrupted_value)\n",
    "print(\"Corrupted Activations Cached:\", len(corrupted_cache))\n",
    "print(\"Corrupted Gradients Cached:\", len(corrupted_grad_cache))\n",
    "\n",
    "print(f\"Clean cache: {clean_cache}\")\n",
    "print(f\"Clean grad cache: {clean_grad_cache}\")\n",
    "print(f\"Corrupted cache: {corrupted_cache}\")\n",
    "print(f\"Corrupted grad cache: {corrupted_grad_cache}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Kiii1hJxtNpD"
   },
   "outputs": [],
   "source": [
    "def get_shape_of_activation(name: str) -> tuple:\n",
    "    shape = clean_cache[name].shape\n",
    "    assert shape == clean_grad_cache[name].shape\n",
    "    return shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGg1aIBoGS0y"
   },
   "source": [
    " ## Validating Attribution vs Activation Patching\n",
    " Let's now compare attribution and activation patching. Generally it's a decent approximation! The main place it fails is MLP0 and the residual stream\n",
    " My fuzzy intuition is that attribution patching works badly for \"big\" things which are poorly modelled as linear approximations, and works well for \"small\" things which are more like incremental changes. Anything involving replacing the embedding is a \"big\" thing, which includes residual streams, and in GPT-2 small MLP0 seems to be used as an \"extended embedding\" (where later layers use MLP0's output instead of the token embedding), so I also count it as big.\n",
    " See more discussion in the accompanying blog post!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rf8KngRdGS0z"
   },
   "source": [
    " First do some refactoring to make attribution patching more generic. We make an attribution cache, which is an ActivationCache where each element is (clean_act - corrupted_act) * corrupted_grad, so that it's the per-element attribution for each activation. Thanks to linearity, we just compute things by adding stuff up along the relevant dimensions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "19FyBg38GS0z"
   },
   "outputs": [],
   "source": [
    "attribution_cache_dict = {}\n",
    "for key in corrupted_grad_cache.cache_dict.keys():\n",
    "    attribution_cache_dict[key] = corrupted_grad_cache.cache_dict[key] * (clean_cache.cache_dict[key] - corrupted_cache.cache_dict[key])\n",
    "attr_cache = ActivationCache(attribution_cache_dict, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCzmQNiPGS01"
   },
   "source": [
    " By block: For each head we patch the starting residual stream, attention output + MLP output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OHFW8nUVGS01"
   },
   "outputs": [],
   "source": [
    "str_tokens = model.to_str_tokens(clean_tokens[0])\n",
    "context_length = len(str_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "background_save": true,
     "referenced_widgets": [
      "8bcd63b781234b9dab0fce5f908e4e2a",
      "b57f3f0eaebb4ab29813ebb6b3996fc5",
      "e7c56de505fe4151a5e3e3594613346f"
     ]
    },
    "id": "jXN6DFjwGS02",
    "outputId": "e1782b89-2fb9-4836-ebcf-91fc5b7a322f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                             | 0/180 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 180/180 [05:05<00:00,  1.69s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 180/180 [02:06<00:00,  1.42it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 180/180 [02:26<00:00,  1.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"189aefdf-9880-4a50-b013-1e8efd310472\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"189aefdf-9880-4a50-b013-1e8efd310472\")) {                    Plotly.newPlot(                        \"189aefdf-9880-4a50-b013-1e8efd310472\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"\\u003c|endoftext|\\u003e_0\",\"When_1\",\" John_2\",\" and_3\",\" Mary_4\",\" went_5\",\" to_6\",\" the_7\",\" shops_8\",\",_9\",\" John_10\",\" gave_11\",\" the_12\",\" bag_13\",\" to_14\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0006505250930786,-0.000247118528932333,9.095357199839782e-06,-0.00036438487586565316,-4.8296013119397685e-05],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0010522603988647,-2.6681953386287205e-05,-2.037225931417197e-05,-0.0004593658959493041,-0.0005942188436165452],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.000266671180725,0.0008678514859639108,0.0005161531735211611,-0.0009936090791597962,-0.0008655021665617824],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.994907796382904,0.005429626442492008,0.0016054145526140928,-0.0006177795003168285,-0.001632432104088366],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9675661325454712,0.031342267990112305,0.002841678448021412,-0.001230491092428565,-0.0009864267194643617],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9675203561782837,0.031000904738903046,0.0017824216047301888,-0.0004854101862292737,-0.0006469786167144775],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9228318929672241,0.051345910876989365,0.004729048814624548,0.0009344724821858108,0.01704668067395687],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6565471887588501,0.023857122287154198,0.002357644261792302,-1.735166006255895e-05,0.31869253516197205],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02730141021311283,0.03142506629228592,0.0018209174741059542,0.0007993510225787759,0.9383879899978638],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.026842212304472923,0.02098124474287033,0.0012512997491285205,0.0003239088400732726,1.0048285722732544],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.005688256584107876,0.014263568446040154,0.0004871889832429588,-8.99802689673379e-05,0.9914220571517944]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"1\",\"x\":[\"\\u003c|endoftext|\\u003e_0\",\"When_1\",\" John_2\",\" and_3\",\" Mary_4\",\" went_5\",\" to_6\",\" the_7\",\" shops_8\",\",_9\",\" John_10\",\" gave_11\",\" the_12\",\" bag_13\",\" to_14\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035457026213407516,-0.000247118528932333,9.095357199839782e-06,-0.00036438487586565316,-4.8296013119397685e-05],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.002983713522553444,7.950886356411502e-05,2.0909254089929163e-05,8.05828531156294e-05,-0.000596366822719574],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.001912206644192338,0.0006665789405815303,0.00039492646465077996,-0.0007046384853310883,-0.00027282716473564506],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15463151037693024,0.003801960265263915,0.0005171599914319813,-0.0001200520055135712,-0.0005607237690128386],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.005405897740274668,0.019581902772188187,0.001007436658255756,-0.00024272187147289515,0.0007938468479551375],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35209742188453674,0.0010526113910600543,0.00022449759126175195,0.000133074150653556,8.293220889754593e-05],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11985946446657181,0.02124413661658764,0.002728103892877698,0.0013409779639914632,0.01797393709421158],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013311105780303478,0.011509587988257408,0.00037465489003807306,-4.111370071768761e-05,0.2976037263870239],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.001500129932537675,0.0173526331782341,0.0005846871645189822,0.0010117662604898214,0.5697312951087952],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00012844255252275616,0.0063013038598001,0.0001413975696777925,0.00031279976246878505,0.27152368426322937],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0009371574269607663,8.679186430526897e-05,0.0003320980176795274,1.5102992847459973e-06,-0.1929771453142166],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.4061789810657501]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"2\",\"x\":[\"\\u003c|endoftext|\\u003e_0\",\"When_1\",\" John_2\",\" and_3\",\" Mary_4\",\" went_5\",\" to_6\",\" the_7\",\" shops_8\",\",_9\",\" John_10\",\" gave_11\",\" the_12\",\" bag_13\",\" to_14\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8507901430130005,-0.0002783313684631139,-7.326629565795884e-05,-0.00047299216384999454,4.007327152066864e-05],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008864549919962883,0.00022140986402519047,0.0001495867472840473,-4.883300789515488e-05,0.0003039057774003595],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01354990154504776,5.8431800425751135e-05,-0.0003297486691735685,-0.0006387894391082227,0.0007728369091637433],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0019473127322271466,0.0004988350556232035,0.0001732816599542275,0.00016841515025589615,0.0004079485952388495],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.019786832854151726,0.004128789063543081,-4.843026181333698e-05,-0.0001701268192846328,0.0007914303569123149],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09652500599622726,-0.001882403390482068,-0.000483765616081655,0.0007101762457750738,-0.00018338389054406434],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.01589932292699814,-0.0008504327270202339,0.00012381096894387156,2.852787474694196e-05,-0.00723765604197979],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010360955260694027,0.0031510882545262575,0.0005312561406753957,0.00023553955543320626,0.008496876806020737],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.01253313384950161,2.23188671952812e-05,-0.0003540476900525391,8.655692363390699e-05,-0.02163161337375641],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0003343466960359365,0.0008097888785414398,1.6512605725438334e-05,0.000129583670059219,0.031624894589185715],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.001359974150545895,-0.00019456011068541557,-9.897494601318613e-05,-0.0001413975696777925,0.028764454647898674],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02044871263206005]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.31999999999999995],\"title\":{\"text\":\"Position\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"title\":{\"text\":\"Layer\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.33999999999999997,0.6599999999999999],\"matches\":\"x\",\"title\":{\"text\":\"Position\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.6799999999999999,0.9999999999999999],\"matches\":\"x\",\"title\":{\"text\":\"Position\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"annotations\":[{\"font\":{},\"showarrow\":false,\"text\":\"Residual Stream\",\"x\":0.15999999999999998,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Attn Output\",\"x\":0.49999999999999994,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"MLP Output\",\"x\":0.8399999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0,\"cmin\":-1,\"cmax\":1},\"title\":{\"text\":\"Activation Patching Per Block\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('189aefdf-9880-4a50-b013-1e8efd310472');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "every_block_act_patch_result = patching.get_act_patch_block_every(model, corrupted_tokens, clean_cache, ioi_metric)\n",
    "imshow(every_block_act_patch_result, facet_col=0, facet_labels=[\"Residual Stream\", \"Attn Output\", \"MLP Output\"], title=\"Activation Patching Per Block\", xaxis=\"Position\", yaxis=\"Layer\", zmax=1, zmin=-1, x= [f\"{tok}_{i}\" for i, tok in enumerate(model.to_str_tokens(clean_tokens[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "az6T_G0zGS02",
    "outputId": "a759be88-2d4c-41c6-a9fa-d95ef41a1ede"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"ff3f3ad3-0cf7-42cf-992a-9ba91571c8e4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ff3f3ad3-0cf7-42cf-992a-9ba91571c8e4\")) {                    Plotly.newPlot(                        \"ff3f3ad3-0cf7-42cf-992a-9ba91571c8e4\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"\\u003c|endoftext|\\u003e_0\",\"When_1\",\" John_2\",\" and_3\",\" Mary_4\",\" went_5\",\" to_6\",\" the_7\",\" shops_8\",\",_9\",\" John_10\",\" gave_11\",\" the_12\",\" bag_13\",\" to_14\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.02465248294174671,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05005310848355293,-0.0003611907013691962,1.3541273801820353e-05,-0.0002876483486033976,-4.1543011320754886e-05],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0883108377456665,-9.53875423874706e-05,-3.1919931643642485e-05,-0.00048538221744820476,-0.0005878621013835073],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11897530406713486,0.0003689214354380965,0.00048030042671598494,-0.0009886263869702816,-0.0008892789483070374],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.17193077504634857,0.0040102992206811905,0.0015210980782285333,-0.000632287934422493,-0.0017019702354446054],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2981642484664917,0.025161467492580414,0.002604920184239745,-0.0011344616068527102,-0.0012104068882763386],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5880972146987915,0.02723023109138012,0.001671633217483759,-0.0004896982572972775,-0.0011541938874870539],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5176085829734802,0.04593571275472641,0.0044746967032551765,0.0009410439524799585,0.015119933523237705],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31773385405540466,0.01970760151743889,0.0021289349533617496,-3.8088663131929934e-05,0.2842131555080414],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.10149668902158737,0.023734280839562416,0.00162934185937047,0.0007824400090612471,0.804681658744812],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.14416925609111786,0.01611384190618992,0.0011326639214530587,0.0002717653987929225,1.1414313316345215],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.1001197099685669,0.013861426152288914,0.0005497926031239331,-0.00010265335004078224,0.9840903282165527]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"1\",\"x\":[\"\\u003c|endoftext|\\u003e_0\",\"When_1\",\" John_2\",\" and_3\",\" Mary_4\",\" went_5\",\" to_6\",\" the_7\",\" shops_8\",\",_9\",\" John_10\",\" gave_11\",\" the_12\",\" bag_13\",\" to_14\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.003820194862782955,-0.0007594451890327036,-4.215197259327397e-05,-0.0003064116754103452,7.108130375854671e-06],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.004389630630612373,5.604577745543793e-05,1.5125113350222819e-05,0.00010058906627818942,-0.0005658612935803831],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0025390833616256714,0.0006071804091334343,0.0003214991884306073,-0.0007672926876693964,-0.0002512678038328886],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10764334350824356,0.0033815454225987196,0.0004669074260164052,-0.00011634316615527496,-0.0006482109311036766],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.006194235756993294,0.01626626029610634,0.0009402884170413017,-0.0002230586833320558,0.0006985251675359905],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2781250774860382,0.000937656732276082,0.00020415746257640421,0.00014139154518488795,-7.320762961171567e-05],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0963827446103096,0.018477313220500946,0.0025752950459718704,0.0013570217415690422,0.0161216352134943],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008937070146203041,0.009925559163093567,0.000363155675586313,-4.0731101762503386e-05,0.2612518072128296],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0016230709152296185,0.016495684161782265,0.0005916826194152236,0.001008282182738185,0.6302468180656433],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00013129357830621302,0.0037536758463829756,0.00014611675578635186,0.00031075754668563604,0.40179386734962463],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0009524293709546328,6.879330612719059e-06,0.00033580922172404826,-2.4050905267358758e-06,-0.1566983461380005],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.4127683639526367]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"2\",\"x\":[\"\\u003c|endoftext|\\u003e_0\",\"When_1\",\" John_2\",\" and_3\",\" Mary_4\",\" went_5\",\" to_6\",\" the_7\",\" shops_8\",\",_9\",\" John_10\",\" gave_11\",\" the_12\",\" bag_13\",\" to_14\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03643864765763283,-0.00034913234412670135,-8.483932469971478e-05,-0.0004152684996370226,5.710824189009145e-05],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.006764624733477831,0.00025573602761141956,0.00013115729962009937,-8.228582009905949e-05,0.00031677779043093324],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.004319871310144663,-1.8601713236421347e-05,-0.00029562864801846445,-0.0006181859062053263,0.0007398900343105197],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.009481175802648067,0.00015555665595456958,0.00017780999769456685,0.00015242156223393977,0.0003593594010453671],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.04226190224289894,0.003517567180097103,-0.00010717731493059546,-0.00020442700770217925,0.0006738072261214256],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06589609384536743,-0.0026417295448482037,-0.0005101235583424568,0.0006988978711888194,-0.00039623078191652894],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0378902293741703,-0.001433578203432262,0.00010811197716975585,3.438693966018036e-05,-0.007840100675821304],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.007204990368336439,0.002793741412460804,0.0005273838760331273,0.00023823334777262062,0.006220208015292883],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.011970714665949345,-9.191228309646249e-05,-0.00035208865301683545,8.58052444527857e-05,-0.02262018620967865],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00025253003695979714,0.0006018629646860063,1.8172169802710414e-05,0.00012882996816188097,0.03556196391582489],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0009344753925688565,-0.00017824559472501278,-9.932599641615525e-05,-0.0001417212188243866,0.02777182124555111],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.020885929465293884]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.31999999999999995],\"title\":{\"text\":\"Position\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"title\":{\"text\":\"Layer\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.33999999999999997,0.6599999999999999],\"matches\":\"x\",\"title\":{\"text\":\"Position\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.6799999999999999,0.9999999999999999],\"matches\":\"x\",\"title\":{\"text\":\"Position\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"annotations\":[{\"font\":{},\"showarrow\":false,\"text\":\"Residual Stream\",\"x\":0.15999999999999998,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Attn Output\",\"x\":0.49999999999999994,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"MLP Output\",\"x\":0.8399999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0,\"cmin\":-1,\"cmax\":1},\"title\":{\"text\":\"Attribution Patching Per Block\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ff3f3ad3-0cf7-42cf-992a-9ba91571c8e4');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_attr_patch_block_every(attr_cache):\n",
    "    resid_pre_attr = einops.reduce(\n",
    "        attr_cache.stack_activation(\"resid_pre\"),\n",
    "        \"layer batch pos d_model -> layer pos\",\n",
    "        \"sum\",\n",
    "    )\n",
    "    attn_out_attr = einops.reduce(\n",
    "        attr_cache.stack_activation(\"attn_out\"),\n",
    "        \"layer batch pos d_model -> layer pos\",\n",
    "        \"sum\",\n",
    "    )\n",
    "    mlp_out_attr = einops.reduce(\n",
    "        attr_cache.stack_activation(\"mlp_out\"),\n",
    "        \"layer batch pos d_model -> layer pos\",\n",
    "        \"sum\",\n",
    "    )\n",
    "\n",
    "    every_block_attr_patch_result = torch.stack([resid_pre_attr, attn_out_attr, mlp_out_attr], dim=0)\n",
    "    return every_block_attr_patch_result\n",
    "every_block_attr_patch_result =  get_attr_patch_block_every(attr_cache)\n",
    "imshow(every_block_attr_patch_result, facet_col=0, facet_labels=[\"Residual Stream\", \"Attn Output\", \"MLP Output\"], title=\"Attribution Patching Per Block\", xaxis=\"Position\", yaxis=\"Layer\", zmax=1, zmin=-1, x= [f\"{tok}_{i}\" for i, tok in enumerate(model.to_str_tokens(clean_tokens[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "HWhzpA9gGS03",
    "outputId": "e9241e9c-bfbf-42a0-dfa5-1f56ee4a6a0a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>                <div id=\"94c05101-e6e0-422c-89ea-6ee42c356e56\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"94c05101-e6e0-422c-89ea-6ee42c356e56\")) {                    Plotly.newPlot(                        \"94c05101-e6e0-422c-89ea-6ee42c356e56\",                        [{\"customdata\":[[\"Layer 0, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 0, Position 1, |When|\"],[\"Layer 0, Position 2, | John|\"],[\"Layer 0, Position 3, | and|\"],[\"Layer 0, Position 4, | Mary|\"],[\"Layer 0, Position 5, | went|\"],[\"Layer 0, Position 6, | to|\"],[\"Layer 0, Position 7, | the|\"],[\"Layer 0, Position 8, | shops|\"],[\"Layer 0, Position 9, |,|\"],[\"Layer 0, Position 10, | John|\"],[\"Layer 0, Position 11, | gave|\"],[\"Layer 0, Position 12, | the|\"],[\"Layer 0, Position 13, | bag|\"],[\"Layer 0, Position 14, | to|\"],[\"Layer 1, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 1, Position 1, |When|\"],[\"Layer 1, Position 2, | John|\"],[\"Layer 1, Position 3, | and|\"],[\"Layer 1, Position 4, | Mary|\"],[\"Layer 1, Position 5, | went|\"],[\"Layer 1, Position 6, | to|\"],[\"Layer 1, Position 7, | the|\"],[\"Layer 1, Position 8, | shops|\"],[\"Layer 1, Position 9, |,|\"],[\"Layer 1, Position 10, | John|\"],[\"Layer 1, Position 11, | gave|\"],[\"Layer 1, Position 12, | the|\"],[\"Layer 1, Position 13, | bag|\"],[\"Layer 1, Position 14, | to|\"],[\"Layer 2, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 2, Position 1, |When|\"],[\"Layer 2, Position 2, | John|\"],[\"Layer 2, Position 3, | and|\"],[\"Layer 2, Position 4, | Mary|\"],[\"Layer 2, Position 5, | went|\"],[\"Layer 2, Position 6, | to|\"],[\"Layer 2, Position 7, | the|\"],[\"Layer 2, Position 8, | shops|\"],[\"Layer 2, Position 9, |,|\"],[\"Layer 2, Position 10, | John|\"],[\"Layer 2, Position 11, | gave|\"],[\"Layer 2, Position 12, | the|\"],[\"Layer 2, Position 13, | bag|\"],[\"Layer 2, Position 14, | to|\"],[\"Layer 3, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 3, Position 1, |When|\"],[\"Layer 3, Position 2, | John|\"],[\"Layer 3, Position 3, | and|\"],[\"Layer 3, Position 4, | Mary|\"],[\"Layer 3, Position 5, | went|\"],[\"Layer 3, Position 6, | to|\"],[\"Layer 3, Position 7, | the|\"],[\"Layer 3, Position 8, | shops|\"],[\"Layer 3, Position 9, |,|\"],[\"Layer 3, Position 10, | John|\"],[\"Layer 3, Position 11, | gave|\"],[\"Layer 3, Position 12, | the|\"],[\"Layer 3, Position 13, | bag|\"],[\"Layer 3, Position 14, | to|\"],[\"Layer 4, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 4, Position 1, |When|\"],[\"Layer 4, Position 2, | John|\"],[\"Layer 4, Position 3, | and|\"],[\"Layer 4, Position 4, | Mary|\"],[\"Layer 4, Position 5, | went|\"],[\"Layer 4, Position 6, | to|\"],[\"Layer 4, Position 7, | the|\"],[\"Layer 4, Position 8, | shops|\"],[\"Layer 4, Position 9, |,|\"],[\"Layer 4, Position 10, | John|\"],[\"Layer 4, Position 11, | gave|\"],[\"Layer 4, Position 12, | the|\"],[\"Layer 4, Position 13, | bag|\"],[\"Layer 4, Position 14, | to|\"],[\"Layer 5, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 5, Position 1, |When|\"],[\"Layer 5, Position 2, | John|\"],[\"Layer 5, Position 3, | and|\"],[\"Layer 5, Position 4, | Mary|\"],[\"Layer 5, Position 5, | went|\"],[\"Layer 5, Position 6, | to|\"],[\"Layer 5, Position 7, | the|\"],[\"Layer 5, Position 8, | shops|\"],[\"Layer 5, Position 9, |,|\"],[\"Layer 5, Position 10, | John|\"],[\"Layer 5, Position 11, | gave|\"],[\"Layer 5, Position 12, | the|\"],[\"Layer 5, Position 13, | bag|\"],[\"Layer 5, Position 14, | to|\"],[\"Layer 6, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 6, Position 1, |When|\"],[\"Layer 6, Position 2, | John|\"],[\"Layer 6, Position 3, | and|\"],[\"Layer 6, Position 4, | Mary|\"],[\"Layer 6, Position 5, | went|\"],[\"Layer 6, Position 6, | to|\"],[\"Layer 6, Position 7, | the|\"],[\"Layer 6, Position 8, | shops|\"],[\"Layer 6, Position 9, |,|\"],[\"Layer 6, Position 10, | John|\"],[\"Layer 6, Position 11, | gave|\"],[\"Layer 6, Position 12, | the|\"],[\"Layer 6, Position 13, | bag|\"],[\"Layer 6, Position 14, | to|\"],[\"Layer 7, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 7, Position 1, |When|\"],[\"Layer 7, Position 2, | John|\"],[\"Layer 7, Position 3, | and|\"],[\"Layer 7, Position 4, | Mary|\"],[\"Layer 7, Position 5, | went|\"],[\"Layer 7, Position 6, | to|\"],[\"Layer 7, Position 7, | the|\"],[\"Layer 7, Position 8, | shops|\"],[\"Layer 7, Position 9, |,|\"],[\"Layer 7, Position 10, | John|\"],[\"Layer 7, Position 11, | gave|\"],[\"Layer 7, Position 12, | the|\"],[\"Layer 7, Position 13, | bag|\"],[\"Layer 7, Position 14, | to|\"],[\"Layer 8, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 8, Position 1, |When|\"],[\"Layer 8, Position 2, | John|\"],[\"Layer 8, Position 3, | and|\"],[\"Layer 8, Position 4, | Mary|\"],[\"Layer 8, Position 5, | went|\"],[\"Layer 8, Position 6, | to|\"],[\"Layer 8, Position 7, | the|\"],[\"Layer 8, Position 8, | shops|\"],[\"Layer 8, Position 9, |,|\"],[\"Layer 8, Position 10, | John|\"],[\"Layer 8, Position 11, | gave|\"],[\"Layer 8, Position 12, | the|\"],[\"Layer 8, Position 13, | bag|\"],[\"Layer 8, Position 14, | to|\"],[\"Layer 9, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 9, Position 1, |When|\"],[\"Layer 9, Position 2, | John|\"],[\"Layer 9, Position 3, | and|\"],[\"Layer 9, Position 4, | Mary|\"],[\"Layer 9, Position 5, | went|\"],[\"Layer 9, Position 6, | to|\"],[\"Layer 9, Position 7, | the|\"],[\"Layer 9, Position 8, | shops|\"],[\"Layer 9, Position 9, |,|\"],[\"Layer 9, Position 10, | John|\"],[\"Layer 9, Position 11, | gave|\"],[\"Layer 9, Position 12, | the|\"],[\"Layer 9, Position 13, | bag|\"],[\"Layer 9, Position 14, | to|\"],[\"Layer 10, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 10, Position 1, |When|\"],[\"Layer 10, Position 2, | John|\"],[\"Layer 10, Position 3, | and|\"],[\"Layer 10, Position 4, | Mary|\"],[\"Layer 10, Position 5, | went|\"],[\"Layer 10, Position 6, | to|\"],[\"Layer 10, Position 7, | the|\"],[\"Layer 10, Position 8, | shops|\"],[\"Layer 10, Position 9, |,|\"],[\"Layer 10, Position 10, | John|\"],[\"Layer 10, Position 11, | gave|\"],[\"Layer 10, Position 12, | the|\"],[\"Layer 10, Position 13, | bag|\"],[\"Layer 10, Position 14, | to|\"],[\"Layer 11, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 11, Position 1, |When|\"],[\"Layer 11, Position 2, | John|\"],[\"Layer 11, Position 3, | and|\"],[\"Layer 11, Position 4, | Mary|\"],[\"Layer 11, Position 5, | went|\"],[\"Layer 11, Position 6, | to|\"],[\"Layer 11, Position 7, | the|\"],[\"Layer 11, Position 8, | shops|\"],[\"Layer 11, Position 9, |,|\"],[\"Layer 11, Position 10, | John|\"],[\"Layer 11, Position 11, | gave|\"],[\"Layer 11, Position 12, | the|\"],[\"Layer 11, Position 13, | bag|\"],[\"Layer 11, Position 14, | to|\"]],\"hovertemplate\":\"facet=0\\u003cbr\\u003eActivation Patch=%{x}\\u003cbr\\u003eAttribution Patch=%{y}\\u003cbr\\u003edata=%{customdata[0]}\\u003cbr\\u003eColor=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0006505250930786,-0.000247118528932333,9.095357199839782e-06,-0.00036438487586565316,-4.8296013119397685e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0010522603988647,-2.6681953386287205e-05,-2.037225931417197e-05,-0.0004593658959493041,-0.0005942188436165452,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.000266671180725,0.0008678514859639108,0.0005161531735211611,-0.0009936090791597962,-0.0008655021665617824,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.994907796382904,0.005429626442492008,0.0016054145526140928,-0.0006177795003168285,-0.001632432104088366,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9675661325454712,0.031342267990112305,0.002841678448021412,-0.001230491092428565,-0.0009864267194643617,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9675203561782837,0.031000904738903046,0.0017824216047301888,-0.0004854101862292737,-0.0006469786167144775,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9228318929672241,0.051345910876989365,0.004729048814624548,0.0009344724821858108,0.01704668067395687,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6565471887588501,0.023857122287154198,0.002357644261792302,-1.735166006255895e-05,0.31869253516197205,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02730141021311283,0.03142506629228592,0.0018209174741059542,0.0007993510225787759,0.9383879899978638,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.026842212304472923,0.02098124474287033,0.0012512997491285205,0.0003239088400732726,1.0048285722732544,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.005688256584107876,0.014263568446040154,0.0004871889832429588,-8.99802689673379e-05,0.9914220571517944],\"xaxis\":\"x\",\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.02465248294174671,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05005310848355293,-0.0003611907013691962,1.3541273801820353e-05,-0.0002876483486033976,-4.1543011320754886e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0883108377456665,-9.53875423874706e-05,-3.1919931643642485e-05,-0.00048538221744820476,-0.0005878621013835073,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11897530406713486,0.0003689214354380965,0.00048030042671598494,-0.0009886263869702816,-0.0008892789483070374,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.17193077504634857,0.0040102992206811905,0.0015210980782285333,-0.000632287934422493,-0.0017019702354446054,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2981642484664917,0.025161467492580414,0.002604920184239745,-0.0011344616068527102,-0.0012104068882763386,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5880972146987915,0.02723023109138012,0.001671633217483759,-0.0004896982572972775,-0.0011541938874870539,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5176085829734802,0.04593571275472641,0.0044746967032551765,0.0009410439524799585,0.015119933523237705,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31773385405540466,0.01970760151743889,0.0021289349533617496,-3.8088663131929934e-05,0.2842131555080414,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.10149668902158737,0.023734280839562416,0.00162934185937047,0.0007824400090612471,0.804681658744812,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.14416925609111786,0.01611384190618992,0.0011326639214530587,0.0002717653987929225,1.1414313316345215,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.1001197099685669,0.013861426152288914,0.0005497926031239331,-0.00010265335004078224,0.9840903282165527],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[\"Layer 0, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 0, Position 1, |When|\"],[\"Layer 0, Position 2, | John|\"],[\"Layer 0, Position 3, | and|\"],[\"Layer 0, Position 4, | Mary|\"],[\"Layer 0, Position 5, | went|\"],[\"Layer 0, Position 6, | to|\"],[\"Layer 0, Position 7, | the|\"],[\"Layer 0, Position 8, | shops|\"],[\"Layer 0, Position 9, |,|\"],[\"Layer 0, Position 10, | John|\"],[\"Layer 0, Position 11, | gave|\"],[\"Layer 0, Position 12, | the|\"],[\"Layer 0, Position 13, | bag|\"],[\"Layer 0, Position 14, | to|\"],[\"Layer 1, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 1, Position 1, |When|\"],[\"Layer 1, Position 2, | John|\"],[\"Layer 1, Position 3, | and|\"],[\"Layer 1, Position 4, | Mary|\"],[\"Layer 1, Position 5, | went|\"],[\"Layer 1, Position 6, | to|\"],[\"Layer 1, Position 7, | the|\"],[\"Layer 1, Position 8, | shops|\"],[\"Layer 1, Position 9, |,|\"],[\"Layer 1, Position 10, | John|\"],[\"Layer 1, Position 11, | gave|\"],[\"Layer 1, Position 12, | the|\"],[\"Layer 1, Position 13, | bag|\"],[\"Layer 1, Position 14, | to|\"],[\"Layer 2, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 2, Position 1, |When|\"],[\"Layer 2, Position 2, | John|\"],[\"Layer 2, Position 3, | and|\"],[\"Layer 2, Position 4, | Mary|\"],[\"Layer 2, Position 5, | went|\"],[\"Layer 2, Position 6, | to|\"],[\"Layer 2, Position 7, | the|\"],[\"Layer 2, Position 8, | shops|\"],[\"Layer 2, Position 9, |,|\"],[\"Layer 2, Position 10, | John|\"],[\"Layer 2, Position 11, | gave|\"],[\"Layer 2, Position 12, | the|\"],[\"Layer 2, Position 13, | bag|\"],[\"Layer 2, Position 14, | to|\"],[\"Layer 3, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 3, Position 1, |When|\"],[\"Layer 3, Position 2, | John|\"],[\"Layer 3, Position 3, | and|\"],[\"Layer 3, Position 4, | Mary|\"],[\"Layer 3, Position 5, | went|\"],[\"Layer 3, Position 6, | to|\"],[\"Layer 3, Position 7, | the|\"],[\"Layer 3, Position 8, | shops|\"],[\"Layer 3, Position 9, |,|\"],[\"Layer 3, Position 10, | John|\"],[\"Layer 3, Position 11, | gave|\"],[\"Layer 3, Position 12, | the|\"],[\"Layer 3, Position 13, | bag|\"],[\"Layer 3, Position 14, | to|\"],[\"Layer 4, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 4, Position 1, |When|\"],[\"Layer 4, Position 2, | John|\"],[\"Layer 4, Position 3, | and|\"],[\"Layer 4, Position 4, | Mary|\"],[\"Layer 4, Position 5, | went|\"],[\"Layer 4, Position 6, | to|\"],[\"Layer 4, Position 7, | the|\"],[\"Layer 4, Position 8, | shops|\"],[\"Layer 4, Position 9, |,|\"],[\"Layer 4, Position 10, | John|\"],[\"Layer 4, Position 11, | gave|\"],[\"Layer 4, Position 12, | the|\"],[\"Layer 4, Position 13, | bag|\"],[\"Layer 4, Position 14, | to|\"],[\"Layer 5, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 5, Position 1, |When|\"],[\"Layer 5, Position 2, | John|\"],[\"Layer 5, Position 3, | and|\"],[\"Layer 5, Position 4, | Mary|\"],[\"Layer 5, Position 5, | went|\"],[\"Layer 5, Position 6, | to|\"],[\"Layer 5, Position 7, | the|\"],[\"Layer 5, Position 8, | shops|\"],[\"Layer 5, Position 9, |,|\"],[\"Layer 5, Position 10, | John|\"],[\"Layer 5, Position 11, | gave|\"],[\"Layer 5, Position 12, | the|\"],[\"Layer 5, Position 13, | bag|\"],[\"Layer 5, Position 14, | to|\"],[\"Layer 6, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 6, Position 1, |When|\"],[\"Layer 6, Position 2, | John|\"],[\"Layer 6, Position 3, | and|\"],[\"Layer 6, Position 4, | Mary|\"],[\"Layer 6, Position 5, | went|\"],[\"Layer 6, Position 6, | to|\"],[\"Layer 6, Position 7, | the|\"],[\"Layer 6, Position 8, | shops|\"],[\"Layer 6, Position 9, |,|\"],[\"Layer 6, Position 10, | John|\"],[\"Layer 6, Position 11, | gave|\"],[\"Layer 6, Position 12, | the|\"],[\"Layer 6, Position 13, | bag|\"],[\"Layer 6, Position 14, | to|\"],[\"Layer 7, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 7, Position 1, |When|\"],[\"Layer 7, Position 2, | John|\"],[\"Layer 7, Position 3, | and|\"],[\"Layer 7, Position 4, | Mary|\"],[\"Layer 7, Position 5, | went|\"],[\"Layer 7, Position 6, | to|\"],[\"Layer 7, Position 7, | the|\"],[\"Layer 7, Position 8, | shops|\"],[\"Layer 7, Position 9, |,|\"],[\"Layer 7, Position 10, | John|\"],[\"Layer 7, Position 11, | gave|\"],[\"Layer 7, Position 12, | the|\"],[\"Layer 7, Position 13, | bag|\"],[\"Layer 7, Position 14, | to|\"],[\"Layer 8, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 8, Position 1, |When|\"],[\"Layer 8, Position 2, | John|\"],[\"Layer 8, Position 3, | and|\"],[\"Layer 8, Position 4, | Mary|\"],[\"Layer 8, Position 5, | went|\"],[\"Layer 8, Position 6, | to|\"],[\"Layer 8, Position 7, | the|\"],[\"Layer 8, Position 8, | shops|\"],[\"Layer 8, Position 9, |,|\"],[\"Layer 8, Position 10, | John|\"],[\"Layer 8, Position 11, | gave|\"],[\"Layer 8, Position 12, | the|\"],[\"Layer 8, Position 13, | bag|\"],[\"Layer 8, Position 14, | to|\"],[\"Layer 9, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 9, Position 1, |When|\"],[\"Layer 9, Position 2, | John|\"],[\"Layer 9, Position 3, | and|\"],[\"Layer 9, Position 4, | Mary|\"],[\"Layer 9, Position 5, | went|\"],[\"Layer 9, Position 6, | to|\"],[\"Layer 9, Position 7, | the|\"],[\"Layer 9, Position 8, | shops|\"],[\"Layer 9, Position 9, |,|\"],[\"Layer 9, Position 10, | John|\"],[\"Layer 9, Position 11, | gave|\"],[\"Layer 9, Position 12, | the|\"],[\"Layer 9, Position 13, | bag|\"],[\"Layer 9, Position 14, | to|\"],[\"Layer 10, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 10, Position 1, |When|\"],[\"Layer 10, Position 2, | John|\"],[\"Layer 10, Position 3, | and|\"],[\"Layer 10, Position 4, | Mary|\"],[\"Layer 10, Position 5, | went|\"],[\"Layer 10, Position 6, | to|\"],[\"Layer 10, Position 7, | the|\"],[\"Layer 10, Position 8, | shops|\"],[\"Layer 10, Position 9, |,|\"],[\"Layer 10, Position 10, | John|\"],[\"Layer 10, Position 11, | gave|\"],[\"Layer 10, Position 12, | the|\"],[\"Layer 10, Position 13, | bag|\"],[\"Layer 10, Position 14, | to|\"],[\"Layer 11, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 11, Position 1, |When|\"],[\"Layer 11, Position 2, | John|\"],[\"Layer 11, Position 3, | and|\"],[\"Layer 11, Position 4, | Mary|\"],[\"Layer 11, Position 5, | went|\"],[\"Layer 11, Position 6, | to|\"],[\"Layer 11, Position 7, | the|\"],[\"Layer 11, Position 8, | shops|\"],[\"Layer 11, Position 9, |,|\"],[\"Layer 11, Position 10, | John|\"],[\"Layer 11, Position 11, | gave|\"],[\"Layer 11, Position 12, | the|\"],[\"Layer 11, Position 13, | bag|\"],[\"Layer 11, Position 14, | to|\"]],\"hovertemplate\":\"facet=1\\u003cbr\\u003eActivation Patch=%{x}\\u003cbr\\u003eAttribution Patch=%{y}\\u003cbr\\u003edata=%{customdata[0]}\\u003cbr\\u003eColor=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.035457026213407516,-0.000247118528932333,9.095357199839782e-06,-0.00036438487586565316,-4.8296013119397685e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.002983713522553444,7.950886356411502e-05,2.0909254089929163e-05,8.05828531156294e-05,-0.000596366822719574,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.001912206644192338,0.0006665789405815303,0.00039492646465077996,-0.0007046384853310883,-0.00027282716473564506,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15463151037693024,0.003801960265263915,0.0005171599914319813,-0.0001200520055135712,-0.0005607237690128386,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.005405897740274668,0.019581902772188187,0.001007436658255756,-0.00024272187147289515,0.0007938468479551375,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35209742188453674,0.0010526113910600543,0.00022449759126175195,0.000133074150653556,8.293220889754593e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11985946446657181,0.02124413661658764,0.002728103892877698,0.0013409779639914632,0.01797393709421158,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.013311105780303478,0.011509587988257408,0.00037465489003807306,-4.111370071768761e-05,0.2976037263870239,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.001500129932537675,0.0173526331782341,0.0005846871645189822,0.0010117662604898214,0.5697312951087952,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00012844255252275616,0.0063013038598001,0.0001413975696777925,0.00031279976246878505,0.27152368426322937,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0009371574269607663,8.679186430526897e-05,0.0003320980176795274,1.5102992847459973e-06,-0.1929771453142166,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.4061789810657501],\"xaxis\":\"x2\",\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.003820194862782955,-0.0007594451890327036,-4.215197259327397e-05,-0.0003064116754103452,7.108130375854671e-06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.004389630630612373,5.604577745543793e-05,1.5125113350222819e-05,0.00010058906627818942,-0.0005658612935803831,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0025390833616256714,0.0006071804091334343,0.0003214991884306073,-0.0007672926876693964,-0.0002512678038328886,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.10764334350824356,0.0033815454225987196,0.0004669074260164052,-0.00011634316615527496,-0.0006482109311036766,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.006194235756993294,0.01626626029610634,0.0009402884170413017,-0.0002230586833320558,0.0006985251675359905,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2781250774860382,0.000937656732276082,0.00020415746257640421,0.00014139154518488795,-7.320762961171567e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0963827446103096,0.018477313220500946,0.0025752950459718704,0.0013570217415690422,0.0161216352134943,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008937070146203041,0.009925559163093567,0.000363155675586313,-4.0731101762503386e-05,0.2612518072128296,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0016230709152296185,0.016495684161782265,0.0005916826194152236,0.001008282182738185,0.6302468180656433,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00013129357830621302,0.0037536758463829756,0.00014611675578635186,0.00031075754668563604,0.40179386734962463,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0009524293709546328,6.879330612719059e-06,0.00033580922172404826,-2.4050905267358758e-06,-0.1566983461380005,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.4127683639526367],\"yaxis\":\"y2\",\"type\":\"scatter\"},{\"customdata\":[[\"Layer 0, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 0, Position 1, |When|\"],[\"Layer 0, Position 2, | John|\"],[\"Layer 0, Position 3, | and|\"],[\"Layer 0, Position 4, | Mary|\"],[\"Layer 0, Position 5, | went|\"],[\"Layer 0, Position 6, | to|\"],[\"Layer 0, Position 7, | the|\"],[\"Layer 0, Position 8, | shops|\"],[\"Layer 0, Position 9, |,|\"],[\"Layer 0, Position 10, | John|\"],[\"Layer 0, Position 11, | gave|\"],[\"Layer 0, Position 12, | the|\"],[\"Layer 0, Position 13, | bag|\"],[\"Layer 0, Position 14, | to|\"],[\"Layer 1, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 1, Position 1, |When|\"],[\"Layer 1, Position 2, | John|\"],[\"Layer 1, Position 3, | and|\"],[\"Layer 1, Position 4, | Mary|\"],[\"Layer 1, Position 5, | went|\"],[\"Layer 1, Position 6, | to|\"],[\"Layer 1, Position 7, | the|\"],[\"Layer 1, Position 8, | shops|\"],[\"Layer 1, Position 9, |,|\"],[\"Layer 1, Position 10, | John|\"],[\"Layer 1, Position 11, | gave|\"],[\"Layer 1, Position 12, | the|\"],[\"Layer 1, Position 13, | bag|\"],[\"Layer 1, Position 14, | to|\"],[\"Layer 2, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 2, Position 1, |When|\"],[\"Layer 2, Position 2, | John|\"],[\"Layer 2, Position 3, | and|\"],[\"Layer 2, Position 4, | Mary|\"],[\"Layer 2, Position 5, | went|\"],[\"Layer 2, Position 6, | to|\"],[\"Layer 2, Position 7, | the|\"],[\"Layer 2, Position 8, | shops|\"],[\"Layer 2, Position 9, |,|\"],[\"Layer 2, Position 10, | John|\"],[\"Layer 2, Position 11, | gave|\"],[\"Layer 2, Position 12, | the|\"],[\"Layer 2, Position 13, | bag|\"],[\"Layer 2, Position 14, | to|\"],[\"Layer 3, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 3, Position 1, |When|\"],[\"Layer 3, Position 2, | John|\"],[\"Layer 3, Position 3, | and|\"],[\"Layer 3, Position 4, | Mary|\"],[\"Layer 3, Position 5, | went|\"],[\"Layer 3, Position 6, | to|\"],[\"Layer 3, Position 7, | the|\"],[\"Layer 3, Position 8, | shops|\"],[\"Layer 3, Position 9, |,|\"],[\"Layer 3, Position 10, | John|\"],[\"Layer 3, Position 11, | gave|\"],[\"Layer 3, Position 12, | the|\"],[\"Layer 3, Position 13, | bag|\"],[\"Layer 3, Position 14, | to|\"],[\"Layer 4, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 4, Position 1, |When|\"],[\"Layer 4, Position 2, | John|\"],[\"Layer 4, Position 3, | and|\"],[\"Layer 4, Position 4, | Mary|\"],[\"Layer 4, Position 5, | went|\"],[\"Layer 4, Position 6, | to|\"],[\"Layer 4, Position 7, | the|\"],[\"Layer 4, Position 8, | shops|\"],[\"Layer 4, Position 9, |,|\"],[\"Layer 4, Position 10, | John|\"],[\"Layer 4, Position 11, | gave|\"],[\"Layer 4, Position 12, | the|\"],[\"Layer 4, Position 13, | bag|\"],[\"Layer 4, Position 14, | to|\"],[\"Layer 5, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 5, Position 1, |When|\"],[\"Layer 5, Position 2, | John|\"],[\"Layer 5, Position 3, | and|\"],[\"Layer 5, Position 4, | Mary|\"],[\"Layer 5, Position 5, | went|\"],[\"Layer 5, Position 6, | to|\"],[\"Layer 5, Position 7, | the|\"],[\"Layer 5, Position 8, | shops|\"],[\"Layer 5, Position 9, |,|\"],[\"Layer 5, Position 10, | John|\"],[\"Layer 5, Position 11, | gave|\"],[\"Layer 5, Position 12, | the|\"],[\"Layer 5, Position 13, | bag|\"],[\"Layer 5, Position 14, | to|\"],[\"Layer 6, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 6, Position 1, |When|\"],[\"Layer 6, Position 2, | John|\"],[\"Layer 6, Position 3, | and|\"],[\"Layer 6, Position 4, | Mary|\"],[\"Layer 6, Position 5, | went|\"],[\"Layer 6, Position 6, | to|\"],[\"Layer 6, Position 7, | the|\"],[\"Layer 6, Position 8, | shops|\"],[\"Layer 6, Position 9, |,|\"],[\"Layer 6, Position 10, | John|\"],[\"Layer 6, Position 11, | gave|\"],[\"Layer 6, Position 12, | the|\"],[\"Layer 6, Position 13, | bag|\"],[\"Layer 6, Position 14, | to|\"],[\"Layer 7, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 7, Position 1, |When|\"],[\"Layer 7, Position 2, | John|\"],[\"Layer 7, Position 3, | and|\"],[\"Layer 7, Position 4, | Mary|\"],[\"Layer 7, Position 5, | went|\"],[\"Layer 7, Position 6, | to|\"],[\"Layer 7, Position 7, | the|\"],[\"Layer 7, Position 8, | shops|\"],[\"Layer 7, Position 9, |,|\"],[\"Layer 7, Position 10, | John|\"],[\"Layer 7, Position 11, | gave|\"],[\"Layer 7, Position 12, | the|\"],[\"Layer 7, Position 13, | bag|\"],[\"Layer 7, Position 14, | to|\"],[\"Layer 8, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 8, Position 1, |When|\"],[\"Layer 8, Position 2, | John|\"],[\"Layer 8, Position 3, | and|\"],[\"Layer 8, Position 4, | Mary|\"],[\"Layer 8, Position 5, | went|\"],[\"Layer 8, Position 6, | to|\"],[\"Layer 8, Position 7, | the|\"],[\"Layer 8, Position 8, | shops|\"],[\"Layer 8, Position 9, |,|\"],[\"Layer 8, Position 10, | John|\"],[\"Layer 8, Position 11, | gave|\"],[\"Layer 8, Position 12, | the|\"],[\"Layer 8, Position 13, | bag|\"],[\"Layer 8, Position 14, | to|\"],[\"Layer 9, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 9, Position 1, |When|\"],[\"Layer 9, Position 2, | John|\"],[\"Layer 9, Position 3, | and|\"],[\"Layer 9, Position 4, | Mary|\"],[\"Layer 9, Position 5, | went|\"],[\"Layer 9, Position 6, | to|\"],[\"Layer 9, Position 7, | the|\"],[\"Layer 9, Position 8, | shops|\"],[\"Layer 9, Position 9, |,|\"],[\"Layer 9, Position 10, | John|\"],[\"Layer 9, Position 11, | gave|\"],[\"Layer 9, Position 12, | the|\"],[\"Layer 9, Position 13, | bag|\"],[\"Layer 9, Position 14, | to|\"],[\"Layer 10, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 10, Position 1, |When|\"],[\"Layer 10, Position 2, | John|\"],[\"Layer 10, Position 3, | and|\"],[\"Layer 10, Position 4, | Mary|\"],[\"Layer 10, Position 5, | went|\"],[\"Layer 10, Position 6, | to|\"],[\"Layer 10, Position 7, | the|\"],[\"Layer 10, Position 8, | shops|\"],[\"Layer 10, Position 9, |,|\"],[\"Layer 10, Position 10, | John|\"],[\"Layer 10, Position 11, | gave|\"],[\"Layer 10, Position 12, | the|\"],[\"Layer 10, Position 13, | bag|\"],[\"Layer 10, Position 14, | to|\"],[\"Layer 11, Position 0, |\\u003c|endoftext|\\u003e|\"],[\"Layer 11, Position 1, |When|\"],[\"Layer 11, Position 2, | John|\"],[\"Layer 11, Position 3, | and|\"],[\"Layer 11, Position 4, | Mary|\"],[\"Layer 11, Position 5, | went|\"],[\"Layer 11, Position 6, | to|\"],[\"Layer 11, Position 7, | the|\"],[\"Layer 11, Position 8, | shops|\"],[\"Layer 11, Position 9, |,|\"],[\"Layer 11, Position 10, | John|\"],[\"Layer 11, Position 11, | gave|\"],[\"Layer 11, Position 12, | the|\"],[\"Layer 11, Position 13, | bag|\"],[\"Layer 11, Position 14, | to|\"]],\"hovertemplate\":\"facet=2\\u003cbr\\u003eActivation Patch=%{x}\\u003cbr\\u003eAttribution Patch=%{y}\\u003cbr\\u003edata=%{customdata[0]}\\u003cbr\\u003eColor=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8507901430130005,-0.0002783313684631139,-7.326629565795884e-05,-0.00047299216384999454,4.007327152066864e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.008864549919962883,0.00022140986402519047,0.0001495867472840473,-4.883300789515488e-05,0.0003039057774003595,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01354990154504776,5.8431800425751135e-05,-0.0003297486691735685,-0.0006387894391082227,0.0007728369091637433,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0019473127322271466,0.0004988350556232035,0.0001732816599542275,0.00016841515025589615,0.0004079485952388495,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.019786832854151726,0.004128789063543081,-4.843026181333698e-05,-0.0001701268192846328,0.0007914303569123149,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09652500599622726,-0.001882403390482068,-0.000483765616081655,0.0007101762457750738,-0.00018338389054406434,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.01589932292699814,-0.0008504327270202339,0.00012381096894387156,2.852787474694196e-05,-0.00723765604197979,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.010360955260694027,0.0031510882545262575,0.0005312561406753957,0.00023553955543320626,0.008496876806020737,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.01253313384950161,2.23188671952812e-05,-0.0003540476900525391,8.655692363390699e-05,-0.02163161337375641,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0003343466960359365,0.0008097888785414398,1.6512605725438334e-05,0.000129583670059219,0.031624894589185715,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.001359974150545895,-0.00019456011068541557,-9.897494601318613e-05,-0.0001413975696777925,0.028764454647898674,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02044871263206005],\"xaxis\":\"x3\",\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03643864765763283,-0.00034913234412670135,-8.483932469971478e-05,-0.0004152684996370226,5.710824189009145e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.006764624733477831,0.00025573602761141956,0.00013115729962009937,-8.228582009905949e-05,0.00031677779043093324,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.004319871310144663,-1.8601713236421347e-05,-0.00029562864801846445,-0.0006181859062053263,0.0007398900343105197,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.009481175802648067,0.00015555665595456958,0.00017780999769456685,0.00015242156223393977,0.0003593594010453671,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.04226190224289894,0.003517567180097103,-0.00010717731493059546,-0.00020442700770217925,0.0006738072261214256,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06589609384536743,-0.0026417295448482037,-0.0005101235583424568,0.0006988978711888194,-0.00039623078191652894,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0378902293741703,-0.001433578203432262,0.00010811197716975585,3.438693966018036e-05,-0.007840100675821304,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.007204990368336439,0.002793741412460804,0.0005273838760331273,0.00023823334777262062,0.006220208015292883,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.011970714665949345,-9.191228309646249e-05,-0.00035208865301683545,8.58052444527857e-05,-0.02262018620967865,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00025253003695979714,0.0006018629646860063,1.8172169802710414e-05,0.00012882996816188097,0.03556196391582489,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0009344753925688565,-0.00017824559472501278,-9.932599641615525e-05,-0.0001417212188243866,0.02777182124555111,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.020885929465293884],\"yaxis\":\"y3\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.31999999999999995],\"title\":{\"text\":\"Activation Patch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Attribution Patch\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.33999999999999997,0.6599999999999999],\"matches\":\"x\",\"title\":{\"text\":\"Activation Patch\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.6799999999999999,0.9999999999999999],\"matches\":\"x\",\"title\":{\"text\":\"Activation Patch\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"annotations\":[{\"font\":{},\"showarrow\":false,\"text\":\"Residual Stream\",\"x\":0.15999999999999998,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Attn Output\",\"x\":0.49999999999999994,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"MLP Output\",\"x\":0.8399999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Color\"}},\"colorscale\":[[0.0,\"rgb(12,51,131)\"],[0.25,\"rgb(10,136,186)\"],[0.5,\"rgb(242,211,56)\"],[0.75,\"rgb(242,143,56)\"],[1.0,\"rgb(217,30,30)\"]]},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Attribution vs Activation Patching Per Block\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('94c05101-e6e0-422c-89ea-6ee42c356e56');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter(y=every_block_attr_patch_result.reshape(3, -1), x=every_block_act_patch_result.reshape(3, -1), facet_col=0, facet_labels=[\"Residual Stream\", \"Attn Output\", \"MLP Output\"], title=\"Attribution vs Activation Patching Per Block\", xaxis=\"Activation Patch\", yaxis=\"Attribution Patch\", hover=[f\"Layer {l}, Position {p}, |{str_tokens[p]}|\" for l in range(model.cfg.n_layers) for p in range(context_length)], color=einops.repeat(torch.arange(model.cfg.n_layers), \"layer -> (layer pos)\", pos=context_length), color_continuous_scale=\"Portland\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPemQ8raGS03"
   },
   "source": [
    " By head: For each head we patch the output, query, key, value or pattern. We do all positions at once so it's not super slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "referenced_widgets": [
      "5268b5ebca7d463c97cbadeb469a39ef",
      "6c5ad096b68e4652aa9efc9cf9ceca59",
      "9c8f0ed9f2144cb0a74678d3a8f281c3",
      "56fbc4e5a66c4498b292553db7b8fab8",
      "299e451b2d904e9496ffa290721b19f9"
     ]
    },
    "id": "68Hj71prGS03",
    "outputId": "cb98a528-b0a2-4b13-8ca5-af2258a6af39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 144/144 [02:00<00:00,  1.20it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 144/144 [01:53<00:00,  1.27it/s]\n",
      " 65%|██████████████████████████████████████████████████████████████████████████████████████▏                                             | 94/144 [01:08<00:37,  1.34it/s]"
     ]
    }
   ],
   "source": [
    "every_head_all_pos_act_patch_result = patching.get_act_patch_attn_head_all_pos_every(model, corrupted_tokens, clean_cache, ioi_metric)\n",
    "imshow(every_head_all_pos_act_patch_result, facet_col=0, facet_labels=[\"Output\", \"Query\", \"Key\", \"Value\", \"Pattern\"], title=\"Activation Patching Per Head (All Pos)\", xaxis=\"Head\", yaxis=\"Layer\", zmax=1, zmin=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "KMbUG4auGS04",
    "outputId": "466f56a6-adb6-4459-f65c-e4b8a843a15a"
   },
   "outputs": [],
   "source": [
    "def get_attr_patch_attn_head_all_pos_every(attr_cache):\n",
    "    head_out_all_pos_attr = einops.reduce(\n",
    "        attr_cache.stack_activation(\"z\"),\n",
    "        \"layer batch pos head_index d_head -> layer head_index\",\n",
    "        \"sum\",\n",
    "    )\n",
    "    head_q_all_pos_attr = einops.reduce(\n",
    "        attr_cache.stack_activation(\"q\"),\n",
    "        \"layer batch pos head_index d_head -> layer head_index\",\n",
    "        \"sum\",\n",
    "    )\n",
    "    head_k_all_pos_attr = einops.reduce(\n",
    "        attr_cache.stack_activation(\"k\"),\n",
    "        \"layer batch pos head_index d_head -> layer head_index\",\n",
    "        \"sum\",\n",
    "    )\n",
    "    head_v_all_pos_attr = einops.reduce(\n",
    "        attr_cache.stack_activation(\"v\"),\n",
    "        \"layer batch pos head_index d_head -> layer head_index\",\n",
    "        \"sum\",\n",
    "    )\n",
    "    head_pattern_all_pos_attr = einops.reduce(\n",
    "        attr_cache.stack_activation(\"pattern\"),\n",
    "        \"layer batch head_index dest_pos src_pos -> layer head_index\",\n",
    "        \"sum\",\n",
    "    )\n",
    "\n",
    "    return torch.stack([head_out_all_pos_attr, head_q_all_pos_attr, head_k_all_pos_attr, head_v_all_pos_attr, head_pattern_all_pos_attr])\n",
    "\n",
    "every_head_all_pos_attr_patch_result = get_attr_patch_attn_head_all_pos_every(attr_cache)\n",
    "imshow(every_head_all_pos_attr_patch_result, facet_col=0, facet_labels=[\"Output\", \"Query\", \"Key\", \"Value\", \"Pattern\"], title=\"Attribution Patching Per Head (All Pos)\", xaxis=\"Head\", yaxis=\"Layer\", zmax=1, zmin=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lvf65z0hGS04",
    "outputId": "f9612d8d-eb26-4fad-8844-4460e3e6b7f3"
   },
   "outputs": [],
   "source": [
    "scatter(y=every_head_all_pos_attr_patch_result.reshape(5, -1), x=every_head_all_pos_act_patch_result.reshape(5, -1), facet_col=0, facet_labels=[\"Output\", \"Query\", \"Key\", \"Value\", \"Pattern\"], title=\"Attribution vs Activation Patching Per Head (All Pos)\", xaxis=\"Activation Patch\", yaxis=\"Attribution Patch\", include_diag=True, hover=head_out_labels, color=einops.repeat(torch.arange(model.cfg.n_layers), \"layer -> (layer head)\", head=model.cfg.n_heads), color_continuous_scale=\"Portland\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKJl3RNcGS05"
   },
   "source": [
    " We see pretty good results in general, but significant errors for heads L5H5 on query and moderate errors for head L10H7 on query and key, and moderate errors for head L11H10 on key. But each of these is fine for pattern and output. My guess is that the problem is that these have pretty saturated attention on a single token, and the linear approximation is thus not great on the attention calculation here, but I'm not sure. When we plot the attention patterns, we do see this!\n",
    " Note that the axis labels are for the *first* prompt's tokens, but each facet is a different prompt, so this is somewhat inaccurate. In particular, every odd facet has indirect object and subject in the opposite order (IO first). But otherwise everything lines up between the prompts (This text is from Neel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Uf8K1LRdGS05",
    "outputId": "b55f4bc6-c7fa-4458-85f6-152292fdeb80"
   },
   "outputs": [],
   "source": [
    "graph_tok_labels = [f\"{tok}_{i}\" for i, tok in enumerate(model.to_str_tokens(clean_tokens[0]))]\n",
    "imshow(clean_cache[\"pattern\", 5][:, 5], x= graph_tok_labels, y=graph_tok_labels, facet_col=0, title=\"Attention for Head L5H5\", facet_name=\"Prompt\")\n",
    "imshow(clean_cache[\"pattern\", 10][:, 7], x= graph_tok_labels, y=graph_tok_labels, facet_col=0, title=\"Attention for Head L10H7\", facet_name=\"Prompt\")\n",
    "imshow(clean_cache[\"pattern\", 11][:, 10], x= graph_tok_labels, y=graph_tok_labels, facet_col=0, title=\"Attention for Head L11H10\", facet_name=\"Prompt\")\n",
    "\n",
    "\n",
    "# [markdown]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a head to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_layer = 5\n",
    "inspect_head = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Pattern Patching\n",
    "https://www.neelnanda.io/mechanistic-interpretability/attribution-patching#attention-pattern-patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "# thanks ChatGPT!\n",
    "\n",
    "# Assuming you want to create a DataFrame for layer 5, head_index 5, and all combinations of dest_pos and src_pos from 0 to 14\n",
    "layer = [inspect_layer]\n",
    "head_index = [inspect_head]\n",
    "dest_pos = [i for i in range(15)]\n",
    "src_pos = [i for i in range(15)]\n",
    "\n",
    "# Create all combinations\n",
    "combinations = product(layer, head_index, dest_pos, src_pos)\n",
    "\n",
    "# Create DataFrame from combinations\n",
    "head_we_want = pd.DataFrame(combinations, columns=[\"layer\", \"head_index\", \"dest_pos\", \"src_pos\"])\n",
    "\n",
    "# Now you can use head_we_want as the index_df in your function\n",
    "our_head_patched = patching.generic_activation_patch(model, corrupted_tokens[:1], clean_cache, ioi_metric, patch_setter=patching.layer_head_dest_src_pos_pattern_patch_setter,activation_name=\"pattern\", index_df=head_we_want)\n",
    "our_head_patched = our_head_patched.reshape((15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgWscSJpCzT_"
   },
   "source": [
    "# Calculating Hessian\n",
    "\n",
    "It can be useful to calculate the diagonal of the Hessian ($\\frac{\\partial^2 L}{\\partial x_i^2}$) when we are doing linear approximations. The higher the magnitude of the second derivative, the worse the linear approximation is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def get_2nd_derivative_attn(model, tokens, metric, hook_name_for_2nd_derivative, batch=0, head=0):\n",
    "    model.reset_hooks()\n",
    "    cache = {}\n",
    "\n",
    "    def forward_cache_hook(act, hook):\n",
    "        act.requires_grad_()\n",
    "        cache[hook.name] = act\n",
    "    model.add_hook(filter_not_qkv_input, forward_cache_hook, \"fwd\")\n",
    "\n",
    "    grad_cache = {}\n",
    "\n",
    "    def backward_cache_hook(act, hook):\n",
    "        grad_cache[hook.name] = act\n",
    "\n",
    "    model.add_hook(filter_not_qkv_input, backward_cache_hook, \"bwd\")\n",
    "\n",
    "    # Compute metric and backward pass\n",
    "    value = metric(model(tokens))\n",
    "    value.backward(create_graph=True)\n",
    "    act_cache = ActivationCache(cache, model)\n",
    "    gradient_cache = ActivationCache(grad_cache, model)\n",
    "    t = torch.empty(15, 15)\n",
    "    for i in range(15):\n",
    "        for j in range(15):\n",
    "            s = (batch, head, i, j)\n",
    "            gradient = torch.autograd.grad(grad_cache[hook_name_for_2nd_derivative][s], cache[hook_name_for_2nd_derivative], allow_unused=True, retain_graph=True)[0][s]\n",
    "            t[i,j] = gradient\n",
    "    model.reset_hooks()\n",
    "    return t, value.item(), act_cache, gradient_cache\n",
    "\n",
    "\n",
    "snd_dir, value, act_cache, grad_cache = get_2nd_derivative_attn(model, clean_tokens, ioi_metric, f'blocks.{inspect_layer}.attn.hook_pattern', batch=0, head=inspect_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIG TODO: the mistake here is that for all these to be consistent with eachother, we either need to sum over all batches (which is costly to activation patch and compute Hessian on), or we just need to do the 0th example (might be better to start)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# snd_dir_to_display = torch.nn.functional.softmax(torch.abs(snd_dir) * 100000, dim=1) # hacky normalization since the display requires it adds up to 1\n",
    "# grad_to_display = torch.nn.functional.softmax(torch.abs(grad_cache['blocks.1.attn.hook_attn_scores'].detach()[0,0]) * 100000, dim=1) # hacky normalization since the display requires it adds up to 1\n",
    "# display(pysvelte.AttentionMulti(tokens=model.to_str_tokens(clean_tokens[0]), attention=torch.stack((act_cache['blocks.1.attn.hook_attn_scores'].detach()[0,0], grad_to_display, snd_dir_to_display)).permute(1,2,0), head_labels=[\"L1H0 act\", \"L1H0 grad\", \"L1H0 hess\"]))\n",
    "\n",
    "# Data to be visualized\n",
    "data = [\n",
    "    our_head_patched - attr_cache[f'blocks.{inspect_layer}.attn.hook_pattern'][0, inspect_head],\n",
    "    our_head_patched,\n",
    "    attr_cache[f'blocks.{inspect_layer}.attn.hook_pattern'][0, inspect_head],\n",
    "    snd_dir,\n",
    "    grad_cache[f'blocks.{inspect_layer}.attn.hook_pattern'][0, inspect_head].detach(),\n",
    "    act_cache[f'blocks.{inspect_layer}.attn.hook_pattern'][0, inspect_head].detach()\n",
    "]\n",
    "\n",
    "# Labels for each facet\n",
    "facet_labels = [\"Activation - attribution\",\"Activation Patched ΔL\",\"Attribution ΔL\", \"Hessian Diag\", \"Gradient\", \"Activations\"]\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 6, figsize=(20, 5))\n",
    "\n",
    "# Plot each facet with its own color scale\n",
    "for i, ax in enumerate(axs):\n",
    "    im = ax.imshow(data[i], cmap='jet')\n",
    "    ax.title.set_text(facet_labels[i])\n",
    "    plt.colorbar(im, ax=ax)\n",
    "\n",
    "plt.suptitle(\"Attribution patching attention pattern derivatives L5H5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e8f9230271643d1b2483c2871fc068d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "200f0d14200b4ca4b5b8a63770e5f273": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38f5eabd8fc044f496c16db6fdd246d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ae8e3252ff94d58a1f91d60f383f981": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8606c99b9a1e41c096356e380e899581",
      "max": 2160,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38f5eabd8fc044f496c16db6fdd246d3",
      "value": 858
     }
    },
    "3b914e82f05b468d9b00a3648e270d5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52fcb107dfa041b38cdd65e29b1ed17d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "621c9c036de342518bfddab234ded453": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9661b11c06d745c1a2c736234a559a2c",
       "IPY_MODEL_3ae8e3252ff94d58a1f91d60f383f981",
       "IPY_MODEL_c5fc9c291b1f4f919bc4a6933c858571"
      ],
      "layout": "IPY_MODEL_3b914e82f05b468d9b00a3648e270d5e"
     }
    },
    "8606c99b9a1e41c096356e380e899581": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9661b11c06d745c1a2c736234a559a2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52fcb107dfa041b38cdd65e29b1ed17d",
      "placeholder": "​",
      "style": "IPY_MODEL_0e8f9230271643d1b2483c2871fc068d",
      "value": " 40%"
     }
    },
    "c5fc9c291b1f4f919bc4a6933c858571": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_200f0d14200b4ca4b5b8a63770e5f273",
      "placeholder": "​",
      "style": "IPY_MODEL_dc917b5f5cc34a4a960fdeb455a9aab4",
      "value": " 858/2160 [01:18&lt;02:05, 10.39it/s]"
     }
    },
    "dc917b5f5cc34a4a960fdeb455a9aab4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
